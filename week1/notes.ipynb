{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Course Outline\n",
    "Week 1 - focus onm time series types and basic forecasting on them. Start preparing timeseries for running ML algorithms on them (e.g. splitting into a training, validation and training sets)\n",
    "Week 2 - forecasting using Dense model vs. Naive prediction\n",
    "Week 3 - Using RNNs to forecast time series, stateful vs. stateless approaches, training on windows on data\n",
    "Week 4 - Forecasting real-world data using CNN\n",
    "\n",
    "## Time series examples\n",
    "TS are  everywhere: stock prices, weather forecasts, historical trends (e.g. Moore's Law)\n",
    "TS is an ordered sequence of values that are usually equally spaced over time.\n",
    "\n",
    "Univariate TS - has a single value at each timestamp; Multivariate TS - has multiple values at each timestamp (e.g. Birth and Death rate or Global Temperature vs. CO2 concentration)\n",
    "\n",
    "## ML applied to time series\n",
    "What types of things can we do with ML over time series?\n",
    "1. Prediction/forecasting base on the data. We can predict future values (e.g. birth vs. death to plan retirement/immigration programs in the country) or past values to se how we got to where we are now (imputation)\n",
    "You might also want to fill in \"gaps in your data\" (e.g. predict missing intermediate values)\n",
    "2. Detect anomalies, for example in website logs so that we can see potential DoS attacks\n",
    "3. Spot pattern to determine what generates series itself: analyse sound waves to spot words in them.\n",
    "\n",
    "## Common patterns in time series\n",
    "There are a number of very common patterns\n",
    "1. Trend - when time series have a specific direction where they are moving to (Moore's Law)\n",
    "2. Seasonality - patterns repeat at predictable intervals (active users on the website)\n",
    "3. Combo of both Trend and Seasonality\n",
    "4. Unpredictable - aka white noise, not much we can do here\n",
    "5. Auto correlated - correlates with a delayed copy of itself, often called a \"lag\"\n",
    "\n",
    "Often in real world data sets we have to deal with all types in one TS.\n",
    "\n",
    "## Train, validation and test sets (to measure performance)\n",
    "*Fixed partitioning* - splits dataset into Training, Validation and Test periods. In case data has seasonality, we have to make sure that every period has all of the seasons.\n",
    "First train model on training period and validate it on validation period. Here we can experiment with the right architecture for training and hyper parameters until we get a desired performance.\n",
    "After that we can retrain the model using train + validation data and test it using test period to see if models performs as well.\n",
    "If it works, we take a usual step of retraining again including the test data.\n",
    "\n",
    "*Roll-forward* partitioning gradually increases training period (e.g. 1 day/week at a time). At each iteration we train the model on a training period and we use it to forcast the following day or week of validation period.\n",
    "\n",
    "## Metrics for evaluating performance\n",
    "```jupyterpython\n",
    "errors = forecasts - actual\n",
    "mse = np.square(errors).mean() # Mean Squared Error - squares the error values to make sure positive and negative actual values are included\n",
    "rmse = np.sqrt(mse) # to get the same scale as original values\n",
    "mae = np.abs(errors).mean() # Mean Absolute Deviation\n",
    "mape = np.abs(errors / x_valid).mean() # Mean Absolute Percentage Error. Mean ratio between an absolute error and absolute value. Gives an idea of the size of the error compare to the values\n",
    "```\n",
    "\n",
    "mae vs. mse: if large values are potentially dangerous and they cost much more than smaller errors than you'd prefer mse.\n",
    "If gain or loss are proportional to the size of the error, then mae would be better.\n",
    "\n",
    "Naive Forecast MAE:\n",
    "```jupyter\n",
    "keras.metrics.mean_absolute_error(x_valid naive_forecast).numpy()\n",
    "```\n",
    "\n",
    "## Moving Average and Differencing\n",
    "MA - is a formal and simple forecasting method, it plots the average of the values over a fixed period of time (e.g. 30 days) also called *averaging window*.\n",
    "Allows eliminating noise and gives a curve that roughly emulates original series, but does not anticipate trend or seasonality.\n",
    "Can sometimes be worse than a naive forecast.\n",
    "\n",
    "To avoid this we can remove a trend and seasonality from a time series with a technique called 'Differencing'.\n",
    "So instead of studying a time series itself, we study the difference between a value of time T and a value of earlier period, e.g. Series(t) - Series(t-365)\n",
    "Having calculated a MA on a differencing, we have to add back the value to get a forecast for the original value:\n",
    "\n",
    "Forecasts = MA of differenced series + series(t-365)\n",
    "\n",
    "There still might be quite a lot of noise. We can smooth past values by using moving average on it:\n",
    "\n",
    "Forecasts = trailing MA of differenced series + centered MA of past series (t-365)\n",
    "\n",
    "## Trailing vs. Centered Windows\n",
    "Note that when we use the trailing window when computing the moving average of present values from t minus 32, t minus one.\n",
    "But when we use a centered window to compute the moving average of past values from one year ago, that's t minus one year minus five days, to t minus one year plus five days.\n",
    "Then moving averages using centered windows can be more accurate than using trailing windows.\n",
    "But we can't use centered windows to smooth present values since we don't know future values.\n",
    "However, to smooth past values we can afford to use centered windows."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}